{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import Libraries\n",
    "import torch\n",
    "import torch.utils.data\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as Function\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "from torchvision import datasets, transforms\n",
    "from torchvision.utils import make_grid , save_image\n",
    "from scipy import stats, integrate\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from sklearn.cluster import KMeans\n",
    "sns.set(color_codes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import pandas as pd\n",
    "\n",
    "# Load data set\n",
    "movies = pd.read_csv('/Users/khanhnamle/Desktop/CSCI799-Graduate-Independent-Study/Codebase/ml-1m/movies.dat', sep='::', header=None, engine='python', encoding='latin-1')\n",
    "users = pd.read_csv('/Users/khanhnamle/Desktop/CSCI799-Graduate-Independent-Study/Codebase/ml-1m/users.dat', sep='::', header=None, engine='python', encoding='latin-1')\n",
    "ratings = pd.read_csv('/Users/khanhnamle/Desktop/CSCI799-Graduate-Independent-Study/Codebase/ml-1m/ratings.dat', sep='::', header=None, engine='python', encoding='latin-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/model_selection/_split.py:2026: FutureWarning: From version 0.21, test_size will always complement train_size unless both are specified.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "700146"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "trainingset, testset = train_test_split(ratings, train_size=0.7)\n",
    "len(trainingset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# convert to array as it is quicker \n",
    "trainingset = np.array(trainingset, dtype='int')\n",
    "testset = np.array(testset, dtype='int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6040 3952\n"
     ]
    }
   ],
   "source": [
    "# get total no. of movies and users in order to then make a matrix of the data\n",
    "nb_users = int(max(max(trainingset[:,0]), max(testset[:,0])))\n",
    "nb_movies = int(max(max(trainingset[:,1]), max(testset[:,1])))\n",
    "print(nb_users, nb_movies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# make matrix of users in lines and movies in columns\n",
    "def convert(data):\n",
    "    new_data = [] # initialise list\n",
    "    for id_users in range(1, nb_users+1):\n",
    "        id_movies = data[:,1][data[:,0] == id_users]\n",
    "        id_ratings = data[:,2][data[:,0] == id_users]\n",
    "        ratings = np.zeros(nb_movies)\n",
    "        ratings[id_movies - 1] = id_ratings\n",
    "        new_data.append(list(ratings))\n",
    "    return new_data\n",
    "\n",
    "trainingset = convert(trainingset)\n",
    "testset = convert(testset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# convert data into torch sensors\n",
    "training_set = torch.FloatTensor(trainingset)\n",
    "test_set = torch.FloatTensor(testset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6039"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new = []\n",
    "\n",
    "for i in range(1, len(training_set)):\n",
    "    x = training_set[i:i+1]\n",
    "    if len(x[x >= 0]) > 0:\n",
    "        new.append(x)\n",
    "    else:\n",
    "        continue\n",
    "\n",
    "len(new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# convert ratings (1-5) into binary ratings 1 (liked) and 0 (not liked)\n",
    "training_set[training_set == 0] = -1 # not rated\n",
    "training_set[training_set == 1] = 0\n",
    "training_set[training_set == 2] = 0\n",
    "training_set[training_set >= 3] = 1\n",
    "\n",
    "test_set[test_set == 0] = -1 # not rated\n",
    "test_set[test_set == 1] = 0\n",
    "test_set[test_set == 2] = 0\n",
    "test_set[test_set >= 3] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Build RBM Class\n",
    "class RBM(nn.Module):\n",
    "    def __init__(self,\n",
    "                 n_vis=3952,\n",
    "                 n_hid=50,\n",
    "                 k=10):\n",
    "        super(RBM, self).__init__()\n",
    "        self.W = nn.Parameter(torch.randn(n_hid,n_vis)*1e-2)\n",
    "        self.v_bias = nn.Parameter(torch.zeros(n_vis))\n",
    "        self.h_bias = nn.Parameter(torch.zeros(n_hid))\n",
    "        self.k = k\n",
    "    \n",
    "    def sample_p(self,p):\n",
    "        return Function.relu(torch.sign(p - Variable(torch.rand(p.size()))))\n",
    "    \n",
    "    def v_to_h(self,v):\n",
    "        p_h = Function.sigmoid(Function.linear(v,self.W,self.h_bias))\n",
    "        sample_h = self.sample_p(p_h)\n",
    "        return p_h,sample_h\n",
    "    \n",
    "    def h_to_v(self,h):\n",
    "        p_v = Function.sigmoid(Function.linear(h,self.W.t(),self.v_bias))\n",
    "        sample_v = self.sample_p(p_v)\n",
    "        return p_v,sample_v\n",
    "        \n",
    "    def forward(self,v):\n",
    "        pre_h1,h1 = self.v_to_h(v)\n",
    "        \n",
    "        h_ = h1\n",
    "        \n",
    "        for _ in range(self.k):\n",
    "            pre_v_,v_ = self.h_to_v(h_)\n",
    "            pre_h_,h_ = self.v_to_h(v_)\n",
    "        \n",
    "        return v,v_, h_\n",
    "    \n",
    "    def free_energy_cost(self,v):\n",
    "        vbias_term = v.mv(self.v_bias)\n",
    "        wx_b = Function.linear(v,self.W,self.h_bias)\n",
    "        hidden_term = wx_b.exp().add(1).log().sum(1)\n",
    "        return (-hidden_term - vbias_term).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rbm = RBM(k=1)\n",
    "train_op = optim.SGD(rbm.parameters(),0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_size_ = 500\n",
    "reconerr = []\n",
    "feerror = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0\n",
      "Reconstructions error:  0.007190789406498273 - free energy loss: -1.786323\n",
      "Epoch: 1\n",
      "Reconstructions error:  0.007198929165800412 - free energy loss: -1.7902832\n",
      "Epoch: 2\n",
      "Reconstructions error:  0.007191801443696022 - free energy loss: -1.7572047\n",
      "Epoch: 3\n",
      "Reconstructions error:  0.007190199568867683 - free energy loss: -1.8578314\n",
      "Epoch: 4\n",
      "Reconstructions error:  0.007152286047736804 - free energy loss: -1.5911001\n",
      "Epoch: 5\n",
      "Reconstructions error:  0.007166666289170583 - free energy loss: -1.6124159\n",
      "Epoch: 6\n",
      "Reconstructions error:  0.007152412707606952 - free energy loss: -1.7643961\n",
      "Epoch: 7\n",
      "Reconstructions error:  0.0071485744168361025 - free energy loss: -1.6217365\n",
      "Epoch: 8\n",
      "Reconstructions error:  0.007139465461174647 - free energy loss: -1.5587044\n",
      "Epoch: 9\n",
      "Reconstructions error:  0.007126982013384501 - free energy loss: -1.5261497\n",
      "Epoch: 10\n",
      "Reconstructions error:  0.007139844819903374 - free energy loss: -1.6287905\n",
      "Epoch: 11\n",
      "Reconstructions error:  0.007121710727612178 - free energy loss: -1.4321035\n",
      "Epoch: 12\n",
      "Reconstructions error:  0.007103196034828822 - free energy loss: -1.4346695\n",
      "Epoch: 13\n",
      "Reconstructions error:  0.007106528927882512 - free energy loss: -1.4940948\n",
      "Epoch: 14\n",
      "Reconstructions error:  0.007108299682537715 - free energy loss: -1.5905908\n",
      "Epoch: 15\n",
      "Reconstructions error:  0.007097334290544192 - free energy loss: -1.4583492\n",
      "Epoch: 16\n",
      "Reconstructions error:  0.0071071187655131025 - free energy loss: -1.5112362\n",
      "Epoch: 17\n",
      "Reconstructions error:  0.007078820218642552 - free energy loss: -1.4023699\n",
      "Epoch: 18\n",
      "Reconstructions error:  0.007085188602407773 - free energy loss: -1.3137869\n",
      "Epoch: 19\n",
      "Reconstructions error:  0.007077767203251521 - free energy loss: -1.4668102\n",
      "Epoch: 20\n",
      "Reconstructions error:  0.00704596812526385 - free energy loss: -1.2630574\n",
      "Epoch: 21\n",
      "Reconstructions error:  0.0070669713119665785 - free energy loss: -1.3300114\n",
      "Epoch: 22\n",
      "Reconstructions error:  0.007073169574141502 - free energy loss: -1.351664\n",
      "Epoch: 23\n",
      "Reconstructions error:  0.0070195260147253675 - free energy loss: -1.2168347\n",
      "Epoch: 24\n",
      "Reconstructions error:  0.0070280879735946655 - free energy loss: -1.1770874\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(25):\n",
    "    loss_ = []\n",
    "    reconstruction_error=0\n",
    "    s=0\n",
    "    for n in range(0, len(training_set)- batch_size_, batch_size_):\n",
    "        vk=training_set[n:n+batch_size_]\n",
    "        vk=Variable(vk)\n",
    "        \n",
    "        v0=training_set[n:n+batch_size_]\n",
    "        v0=Variable(v0)\n",
    "              \n",
    "        ph0,_=rbm.v_to_h(v0)\n",
    "        for k in range(1):\n",
    "            _,hk =rbm.v_to_h(vk)\n",
    "            _,vk=rbm.h_to_v(hk)\n",
    "            \n",
    "            vk[v0<0] = v0[v0<0]\n",
    "        phk,_ = rbm.v_to_h(vk)\n",
    "        \n",
    "        loss = rbm.free_energy_cost(v0) - rbm.free_energy_cost(vk)\n",
    "        loss_.append(loss.data)\n",
    "        train_op.zero_grad()\n",
    "        \n",
    "        loss.backward()\n",
    "        train_op.step()\n",
    "    \n",
    "        reconstruction_error+=torch.mean(torch.abs(v0-vk))\n",
    "        s+=1\n",
    "        \n",
    "    reconerr.append(reconstruction_error.data.numpy()/s)\n",
    "    feerror.append(np.mean(loss_))\n",
    "    \n",
    "    print('Epoch: ' + str(epoch))\n",
    "    print ('Reconstructions error:  ' + str(reconstruction_error.data.numpy()/s)+ \n",
    "          ' - free energy loss: ' + str(np.mean(loss_)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-10.24488\n",
      "-8.44695\n",
      "-7.0894523\n",
      "-6.059626\n",
      "-5.461384\n",
      "-4.8375754\n",
      "-4.359697\n",
      "-4.0628915\n",
      "-3.718146\n",
      "-3.5231807\n",
      "-3.2618675\n",
      "-3.1332996\n",
      "-2.8576214\n",
      "-2.8217914\n",
      "-2.6375186\n",
      "-2.6157455\n",
      "-2.3546715\n",
      "-2.3841145\n",
      "-2.2817333\n",
      "-2.3969917\n",
      "-2.116764\n",
      "-2.1666043\n",
      "-1.9446703\n",
      "-2.0644543\n",
      "-2.0678883\n",
      "-2.0148876\n",
      "-1.9183744\n",
      "-1.786323\n",
      "-1.7902832\n",
      "-1.7572047\n",
      "-1.8578314\n",
      "-1.5911001\n",
      "-1.6124159\n",
      "-1.7643961\n",
      "-1.6217365\n",
      "-1.5587044\n",
      "-1.5261497\n",
      "-1.6287905\n",
      "-1.4321035\n",
      "-1.4346695\n",
      "-1.4940948\n",
      "-1.5905908\n",
      "-1.4583492\n",
      "-1.5112362\n",
      "-1.4023699\n",
      "-1.3137869\n",
      "-1.4668102\n",
      "-1.2630574\n",
      "-1.3300114\n",
      "-1.351664\n",
      "-1.2168347\n",
      "-1.1770874\n"
     ]
    }
   ],
   "source": [
    "for i in feerror:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Keep track of time\n",
    "import time\n",
    "start_time = time.time()\n",
    "\n",
    "test_loss = 0\n",
    "s = 0 \n",
    "vis1 = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reconstructions error:  tensor(0.2373, grad_fn=<DivBackward0>)\n",
      "--- training time is 90.7833640575409 seconds ---\n"
     ]
    }
   ],
   "source": [
    "# Testing\n",
    "for id_user in range(0, nb_users): # batch learning\n",
    "    v = test_set[id_user:id_user+ 1]  # training set inputs are used to activate neurons of my RBM\n",
    "    vt = test_set[id_user:id_user + 1] # target\n",
    "    \n",
    "    v = Variable(v)\n",
    "    vt = Variable(vt)\n",
    "    if len(vt[vt>=0])>0:\n",
    "        _,h = rbm.v_to_h(v)\n",
    "        _,v = rbm.h_to_v(h)\n",
    "        \n",
    "        test_loss += torch.mean(torch.abs(vt[vt>=0]-v[vt>=0]))   # update train loss\n",
    "        s += 1\n",
    "    \n",
    "    v = v.data.numpy()\n",
    "    vis1.append(v)\n",
    "\n",
    "\n",
    "print ('Reconstructions error:  ' +  str(test_loss/s))\n",
    "print(\"--- training time is %s seconds ---\" % (time.time() - start_time))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
